{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Loading dataset\n",
      "[!] Preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19717 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/xiaoxin/miniconda3/envs/gnn_ak/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████| 19717/19717 [01:27<00:00, 225.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  88.83961486816406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Generating node embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1233/1233 [01:54<00:00, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  118.73420071601868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (convs): ModuleList(\n",
       "    (0): GCNConv(768, 128)\n",
       "    (1): GCNConv(128, 128)\n",
       "    (2): GCNConv(128, 128)\n",
       "    (3): GCNConv(128, 3)\n",
       "  )\n",
       "  (bns): ModuleList(\n",
       "    (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from bert import preprocessing, generate_node_embeddings\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from load_pubmed import get_pubmed_casestudy\n",
    "from main_pubmed_gnn import GCN\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "\n",
    "# load data\n",
    "print(\"[!] Loading dataset\")\n",
    "f = open('pubmed.json')\n",
    "pubmed = json.load(f)\n",
    "df_pubmed = pd.DataFrame.from_dict(pubmed)\n",
    "\n",
    "# Preprocess\n",
    "print(\"[!] Preprocessing\")\n",
    "start = time.time()\n",
    "AB = df_pubmed['AB'].fillna(\"\")\n",
    "TI = df_pubmed['TI'].fillna(\"\")\n",
    "text = []\n",
    "for ti, ab in zip(TI, AB):\n",
    "    t = 'Title: ' + ti + '\\n'+'Abstract: ' + ab\n",
    "    # t = ti + ab\n",
    "    text.append(t)\n",
    "token_id = []\n",
    "attention_masks = []\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased', do_lower_case=True)\n",
    "for sample in tqdm(text):\n",
    "    encoding_dict = preprocessing(sample, tokenizer)\n",
    "    token_id.append(encoding_dict['input_ids'])\n",
    "    attention_masks.append(encoding_dict['attention_mask'])\n",
    "token_id = torch.cat(token_id, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "print(\"Time: \", time.time()-start)\n",
    "\n",
    "# Prepare DataLoader\n",
    "dataset = TensorDataset(token_id, attention_masks)\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False,\n",
    "    sampler=SequentialSampler(dataset),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Load the BertForSequenceClassification model\n",
    "bert = BertModel.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=True,\n",
    ")\n",
    "\n",
    "# Run on GPU\n",
    "print(\"[!] Generating node embeddings\")\n",
    "start = time.time()\n",
    "bert.cuda()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "features = generate_node_embeddings(bert, dataloader, device)\n",
    "print(\"Time: \", time.time()-start)\n",
    "\n",
    "data, data_pubid = get_pubmed_casestudy()\n",
    "data.x = features\n",
    "gnn_model = GCN(\n",
    "    in_channels=data.x.shape[1], hidden_channels=128, out_channels=3, num_layers=4, dropout=0)\n",
    "gnn_model.cuda()\n",
    "\n",
    "# print(\"[!] Start training\")\n",
    "\n",
    "# data.cuda()\n",
    "# optimizer_gnn = torch.optim.Adam(gnn_model.parameters(), lr=0.001)\n",
    "# optimizer_lm = torch.optim.Adam(bert.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19717, 500])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from main_pubmed_gnn import GCN, train, test, get_pubmed_casestudy\n",
    "import torch\n",
    "\n",
    "data, data_pubid = get_pubmed_casestudy()\n",
    "gnn_model = GCN(\n",
    "    in_channels=data.x.shape[1], hidden_channels=128, out_channels=3, num_layers=4, dropout=0)\n",
    "gnn_model.cuda()\n",
    "\n",
    "data.cuda()\n",
    "data.x.requires_grad = True\n",
    "    # X.retain_grad()\n",
    "optimizer = torch.optim.Adam(gnn_model.parameters(), lr=0.001)\n",
    "loss = train(gnn_model, data, optimizer)\n",
    "data.x.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1385e-05,  2.2168e-05, -1.6015e-05, -1.8941e-06, -9.6117e-06,\n",
       "        -4.6854e-06, -8.3772e-06, -1.0540e-05,  1.8001e-05, -7.0987e-06,\n",
       "        -2.2527e-06, -1.5540e-07,  1.2920e-05,  6.0613e-06,  1.7150e-05,\n",
       "        -4.0121e-06, -1.1031e-05, -9.1760e-06, -7.0928e-06,  1.7955e-06,\n",
       "         1.2213e-05, -1.6607e-05,  3.1364e-06,  1.4918e-05, -9.0528e-06,\n",
       "         2.2131e-06, -6.3234e-06,  1.7106e-05,  7.9889e-06, -5.8155e-06,\n",
       "         6.2206e-06,  2.4634e-06,  1.3613e-05, -5.9173e-07,  3.7671e-06,\n",
       "        -2.2502e-06,  8.5266e-06,  1.8880e-05,  3.7765e-06, -4.8494e-07,\n",
       "         1.8441e-06,  1.1724e-05, -1.0196e-05, -3.8486e-06,  6.4225e-06,\n",
       "         1.5954e-05, -1.3176e-06,  7.6001e-07,  6.3990e-06,  1.1572e-05,\n",
       "        -6.5945e-06,  7.0943e-06, -3.2693e-06, -1.7289e-05,  6.2373e-06,\n",
       "         1.6362e-06, -9.7330e-06,  7.6515e-06,  8.0297e-07, -1.1037e-05,\n",
       "        -1.5831e-05,  2.1412e-06, -9.0578e-06,  9.8477e-06, -5.3620e-06,\n",
       "        -6.0833e-06, -4.7885e-08,  5.4665e-07, -5.5931e-06,  6.8400e-06,\n",
       "        -2.6593e-06,  4.9771e-06,  1.4605e-06,  4.5687e-06, -2.0650e-06,\n",
       "        -3.2664e-07, -1.0628e-05,  1.3860e-05,  9.9042e-06,  1.3364e-05,\n",
       "        -4.4291e-06, -1.9648e-05, -9.3402e-06,  3.1567e-06, -1.4115e-05,\n",
       "         2.8457e-06,  1.0520e-06,  1.3556e-06,  6.5906e-06, -1.7591e-05,\n",
       "         7.4570e-06, -8.1265e-06,  6.3841e-07,  5.7842e-06,  4.0292e-06,\n",
       "         3.2705e-06,  1.4802e-05,  2.0191e-07,  2.0131e-06, -8.9491e-06,\n",
       "         1.2848e-05,  4.6911e-06, -4.2692e-06,  7.5841e-07,  9.8102e-06,\n",
       "         1.2703e-05, -8.0934e-06,  1.3953e-05, -1.2778e-06, -5.5500e-06,\n",
       "         9.9712e-06, -1.0974e-06, -8.6690e-06, -4.5132e-06,  9.6597e-07,\n",
       "        -2.1708e-05,  9.4884e-06,  9.9265e-07,  1.0531e-06, -1.6135e-05,\n",
       "         2.2877e-06, -1.1750e-05,  1.6931e-06,  6.8407e-06,  1.1811e-06,\n",
       "        -6.0544e-06, -1.1519e-05, -1.3627e-05, -1.9029e-05,  1.0250e-06,\n",
       "        -5.0129e-06,  5.6671e-06, -3.8923e-06, -2.3000e-06,  1.8822e-06,\n",
       "        -5.6016e-06, -1.7530e-05,  1.0616e-05, -5.9365e-06, -1.5291e-05,\n",
       "         1.6043e-06, -5.9248e-06,  9.0092e-07, -1.3285e-05, -7.7059e-06,\n",
       "        -5.3443e-06,  7.9756e-07, -7.9741e-07, -7.9684e-07,  3.5915e-06,\n",
       "        -8.8670e-06, -2.3706e-06, -1.7624e-06, -8.7353e-06,  3.2283e-06,\n",
       "        -1.5807e-05, -1.6230e-06,  4.6604e-06, -3.0607e-06,  3.0786e-06,\n",
       "        -4.0824e-06, -3.7641e-06, -1.7841e-06,  4.1029e-06, -2.9335e-06,\n",
       "         6.4044e-06, -5.8935e-06,  1.4489e-05, -7.8675e-06,  1.7350e-05,\n",
       "        -5.6961e-06, -2.4468e-06, -9.2127e-06,  9.5885e-06, -2.0385e-05,\n",
       "        -7.0108e-07,  3.0531e-06,  3.1342e-06,  8.6771e-06,  9.8861e-06,\n",
       "         5.0158e-06,  3.7357e-06,  1.4841e-06,  5.6644e-06,  8.3075e-07,\n",
       "        -1.7548e-05, -4.9515e-06, -4.7259e-07,  6.6259e-06, -1.3224e-06,\n",
       "         1.2362e-05,  8.1076e-06,  6.4101e-06, -1.0666e-06, -5.2028e-06,\n",
       "         4.2190e-06, -3.4998e-06, -4.9406e-06, -1.0685e-05, -6.1375e-06,\n",
       "        -5.1322e-06, -4.9155e-06,  7.2505e-06,  7.1304e-06,  2.9293e-07,\n",
       "         7.9611e-06,  8.1846e-06,  7.6482e-09,  4.2109e-06, -8.2660e-06,\n",
       "         2.4748e-06, -8.2885e-07,  5.2646e-06, -1.6318e-06, -3.3934e-06,\n",
       "         1.1328e-05,  1.6196e-05, -1.2646e-05, -5.0274e-06, -1.7078e-06,\n",
       "         4.6818e-06, -4.6384e-07, -2.9933e-06, -1.7047e-05,  6.3528e-06,\n",
       "         1.4630e-06, -2.1072e-07, -4.2770e-06,  1.0155e-05,  8.3088e-06,\n",
       "        -9.4821e-06,  1.5975e-05, -6.0981e-06, -4.0790e-06, -1.7450e-06,\n",
       "        -4.9790e-06,  7.1618e-06, -5.8044e-07,  2.5738e-06,  6.7665e-07,\n",
       "         9.6317e-06, -3.9586e-06,  5.9917e-06,  1.2099e-05, -6.2738e-06,\n",
       "         7.8098e-06,  8.9713e-06, -3.2292e-05,  1.4152e-06, -1.0719e-05,\n",
       "        -2.8568e-06,  1.2868e-05,  5.3080e-06,  5.9420e-07,  3.1032e-06,\n",
       "         9.0624e-06,  8.5864e-06, -4.5384e-06, -3.0909e-06,  1.1186e-07,\n",
       "         2.6379e-06, -3.3822e-06, -1.1392e-05, -3.1900e-06, -2.2901e-06,\n",
       "         1.7675e-05,  2.4108e-06,  4.0082e-06,  5.9191e-06, -9.4513e-07,\n",
       "        -4.4871e-06, -5.4668e-06,  8.7461e-06,  9.6373e-07, -4.5708e-06,\n",
       "        -1.0170e-05, -4.0234e-06,  1.0902e-05,  1.3897e-06,  5.8114e-06,\n",
       "        -2.1424e-06,  4.5259e-06,  2.0831e-05,  5.7315e-06, -1.9883e-06,\n",
       "         2.4820e-06,  3.1932e-06, -1.4568e-05,  6.4294e-06,  3.4361e-06,\n",
       "         5.9389e-06, -9.3476e-06,  5.7801e-07,  5.2551e-06,  6.6004e-07,\n",
       "         2.8783e-06, -3.9767e-06, -6.4953e-06, -8.1046e-06,  1.2724e-05,\n",
       "        -1.3478e-07, -1.9927e-05,  4.1959e-06,  2.5983e-06,  5.8516e-06,\n",
       "        -8.4578e-06, -2.9133e-07,  2.4261e-06,  1.3220e-06, -1.1966e-05,\n",
       "        -1.3546e-05, -4.6845e-06, -2.8218e-06, -1.4686e-06,  2.5052e-06,\n",
       "         2.0367e-06,  5.1895e-06, -5.6617e-06,  4.2449e-06,  9.6510e-06,\n",
       "         4.1555e-06, -7.4331e-06, -1.7010e-05,  3.5206e-06, -4.0407e-06,\n",
       "         1.2578e-06,  3.0946e-06,  4.3074e-07,  1.0558e-05,  1.0497e-05,\n",
       "         1.4439e-05,  2.3521e-06, -3.0205e-07, -5.2636e-06, -1.3463e-05,\n",
       "         6.0413e-06,  2.2259e-06, -9.6253e-06, -7.2611e-06, -5.8832e-06,\n",
       "        -9.6351e-06, -1.7475e-06,  6.0032e-06,  8.6032e-06, -3.9724e-06,\n",
       "        -4.1164e-06, -2.6802e-06, -6.3850e-06, -1.1704e-05,  1.6715e-05,\n",
       "        -1.2239e-05,  7.4524e-07,  7.4485e-07, -4.7243e-06, -3.2772e-06,\n",
       "        -5.0272e-07, -1.3862e-05, -3.1079e-06,  6.9988e-06, -3.0532e-06,\n",
       "        -4.6165e-06, -1.3588e-05, -7.8640e-06, -6.9561e-06, -1.9898e-06,\n",
       "        -4.7629e-06, -1.2798e-06,  2.8216e-07, -9.1484e-06, -7.7708e-06,\n",
       "        -2.9954e-06, -1.7841e-06, -1.1104e-06,  2.9552e-07,  2.8887e-06,\n",
       "        -1.1145e-05,  1.4092e-06,  2.5948e-06,  6.3520e-06,  9.6476e-06,\n",
       "         7.6261e-07,  1.3062e-05,  3.5774e-06, -7.2854e-06,  1.1163e-06,\n",
       "        -1.7662e-07,  1.1305e-05, -7.7348e-06, -1.4522e-06, -4.7462e-06,\n",
       "         1.0606e-06,  1.2291e-05,  2.9072e-06,  8.5563e-06,  1.0632e-05,\n",
       "         5.1501e-06, -1.1468e-05, -7.2688e-07,  1.4363e-05, -2.6690e-06,\n",
       "        -4.7761e-06, -1.4228e-05, -4.3683e-06, -1.1526e-05,  6.6737e-06,\n",
       "        -4.4504e-06, -5.2288e-06, -7.9553e-06,  7.1259e-06, -6.6362e-06,\n",
       "        -5.3212e-06, -2.2438e-06, -1.4217e-06,  1.1609e-06,  2.1241e-05,\n",
       "        -1.9815e-05,  7.8768e-06, -5.6813e-06,  4.4253e-06,  6.3964e-06,\n",
       "        -4.8425e-07,  6.8196e-06, -3.0916e-06,  2.3112e-05,  1.5154e-06,\n",
       "        -5.8279e-06, -2.8616e-06,  1.0304e-05, -1.0329e-05, -6.9288e-07,\n",
       "         2.4567e-06, -9.4120e-07, -1.3224e-05, -6.4178e-06, -1.7052e-05,\n",
       "        -9.2812e-06, -1.3655e-06, -6.6064e-06,  6.6365e-06, -5.4358e-06,\n",
       "         1.3140e-06, -3.4754e-06,  3.9106e-06,  4.8838e-06,  1.1259e-06,\n",
       "        -2.7909e-06, -9.1539e-06,  3.2177e-06,  5.5337e-06, -3.5400e-06,\n",
       "         4.9460e-06,  2.6977e-06, -4.4419e-06,  6.2607e-06,  5.6700e-06,\n",
       "         5.3930e-06,  1.9707e-06, -2.0518e-05,  5.6287e-06,  1.6883e-06,\n",
       "        -4.7116e-06, -2.5441e-06,  7.5897e-06,  7.3058e-06, -3.5344e-06,\n",
       "         2.1062e-05, -4.2937e-06,  3.0899e-06, -7.0718e-07,  1.5530e-05,\n",
       "         2.7844e-06, -8.3681e-06, -2.2186e-06, -8.8850e-07,  2.4548e-06,\n",
       "        -1.4969e-05, -3.0026e-06, -1.3382e-05, -4.7176e-06,  3.2420e-06,\n",
       "        -3.9035e-06, -1.3254e-05, -3.1441e-05, -5.9534e-06,  1.2126e-05,\n",
       "         7.8505e-06, -1.7787e-06,  2.7160e-07, -9.0776e-07, -1.0806e-06,\n",
       "         8.2977e-06,  6.6170e-06,  1.0681e-05,  1.3623e-05,  1.2016e-06,\n",
       "         7.5002e-06,  7.8302e-07,  4.5815e-06,  6.6584e-06,  1.9074e-07],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.grad.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51be54f33a41cac59dddcbb17816709b9089a1f775c651da797be6dbfb614eca"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('gnn_ak')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
